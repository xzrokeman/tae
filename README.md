# Really? Written by LLM? 
 `DeepSeek-R1` has become the new benchmark for LLM capabilities. Due to its complete open-source nature, various cloud service providers have deployed this model and offered significant discounts to attract customers, making it essentially free during the Lunar New Year in 2025. To reduce my workload in the first quarter, I  used multiple models(including `DeepSeek-R1`) to generate this browser extension, taking the opportunity to experience the practical capabilities of inference models. It's worth noting that models under the MOE architecture continue to impress (the last one was mistral 8Ã—7b), and with added function calling and web search capabilities, they can achieve even more.  
